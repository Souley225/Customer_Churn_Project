# Construction d'un score d'attrition: Telco Customer Churn

![Python Version](https://img.shields.io/badge/python-3.11-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![MLflow](https://img.shields.io/badge/MLflow-tracking-orange.svg)
![Docker](https://img.shields.io/badge/docker-compose-2496ED.svg)
![DVC](https://img.shields.io/badge/DVC-pipeline-945DD6.svg)

> **Ce projet implÃ©mente un pipeline complet de Machine Learning pour la prÃ©diction du churn client sur le dataset Telco Customer Churn avec une architecture MLOps moderne.**

---

## ğŸ“Š PrÃ©sentation gÃ©nÃ©rale

Ce projet utilise le dataset public **Telco Customer Churn** de Kaggle pour construire, suivre, versionner et dÃ©ployer un modÃ¨le de classification de maniÃ¨re reproductible.

### ğŸ› ï¸ Stack Technologique

| Outil | Usage |
|-------|-------|
| ğŸ”§ **Hydra** | Gestion des configurations |
| ğŸ“¦ **DVC** | Versioning des donnÃ©es et reproductibilitÃ© |
| ğŸ“ˆ **MLflow** | Suivi des expÃ©riences et registre de modÃ¨les |
| ğŸ¯ **Optuna** | Optimisation des hyperparamÃ¨tres |
| ğŸš€ **FastAPI** | API de prÃ©diction |
| ğŸ¨ **Streamlit** | Interface utilisateur |
| ğŸ³ **Docker Compose** | DÃ©ploiement conteneurisÃ© |
| âš™ï¸ **GitHub Actions** | CI/CD |

---

## ğŸ“‹ Informations principales

?> **Dataset**: `blastchar/telco-customer-churn` (Kaggle)

?> **Variable cible**: `Churn` (Yes/No)

- **Langage**: Python 3.11
- **Gestionnaire de paquets**: Poetry
- **Suivi d'expÃ©riences**: MLflow (local ou distant)
- **Version des donnÃ©es**: DVC
- **Optimisation**: Optuna

---

## ğŸ“ Structure du projet

```
mlops-classification-project/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ dvc.yaml
â”œâ”€â”€ ğŸ“„ params.yaml
â”œâ”€â”€ ğŸ“„ compose.yaml
â”œâ”€â”€ ğŸ³ docker/
â”‚   â”œâ”€â”€ Dockerfile.train
â”‚   â””â”€â”€ Dockerfile.app
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ ui/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ âš™ï¸ configs/
â”‚   â”œâ”€â”€ data.yaml
â”‚   â”œâ”€â”€ model.yaml
â”‚   â””â”€â”€ train.yaml
â”œâ”€â”€ ğŸ§ª tests/
â””â”€â”€ ğŸ”„ .github/workflows/
```

---

## ğŸ’» Installation locale

### PrÃ©requis

!> **Attention**: Assurez-vous d'avoir tous les outils suivants installÃ©s avant de commencer.

- âœ… Python 3.11 ou plus (recommandÃ©: pyenv)
- âœ… Poetry
- âœ… Git
- âœ… DVC
- âœ… Docker et Docker Compose
- âœ… Un compte Kaggle avec le fichier `~/.kaggle/kaggle.json`

### ğŸš€ Ã‰tapes d'installation

#### 1ï¸âƒ£ Installation de Python

```bash
# Installation de Python
pyenv install 3.11.9
pyenv local 3.11.9
```

#### 2ï¸âƒ£ Installation de Poetry

```bash
# Installation de Poetry
curl -sSL https://install.python-poetry.org | python3 -
poetry --version
```

#### 3ï¸âƒ£ Clonage du projet

```bash
# Clonage du projet
git clone https://github.com/Souley225/Customer_Churn_Project
cd Customer_Churn_Project

# Installation des dÃ©pendances
poetry install
```

#### 4ï¸âƒ£ Initialisation de DVC

```bash
# Initialisation de DVC
dvc init

# VÃ©rification des hooks
poetry run pre-commit install
```

### ğŸ”‘ Configuration de l'API Kaggle

CrÃ©ez un fichier `~/.kaggle/kaggle.json` contenant vos identifiants Kaggle:

```bash
chmod 600 ~/.kaggle/kaggle.json
```

---

## ğŸ”„ ExÃ©cution du pipeline complet

Le pipeline est entiÃ¨rement automatisÃ© via **DVC** et **Hydra**.

```bash
# ExÃ©cution complÃ¨te du pipeline
dvc repro
```

### ğŸ“ Ã‰tapes du pipeline

1. **ğŸ“¥ TÃ©lÃ©chargement** des donnÃ©es depuis Kaggle
2. **âœ‚ï¸ DÃ©coupage** en ensembles d'entraÃ®nement, validation et test
3. **ğŸ”¨ Feature Engineering** (tenure_bucket, num_services, total_spend_proxy, etc.)
4. **ğŸ¯ EntraÃ®nement** avec Optuna et suivi MLflow
5. **ğŸ“Š Ã‰valuation** du modÃ¨le sur le jeu de test
6. **ğŸ’¾ Enregistrement** du meilleur modÃ¨le dans le registre MLflow

---

## ğŸ³ Lancement des services avec Docker Compose

```bash
# Construction des images Docker
docker compose build

# Lancement de l'infrastructure
make up
```

### ğŸŒ Services accessibles

| Service | URL | Description |
|---------|-----|-------------|
| ğŸ“ˆ **MLflow UI** | [http://localhost:5000](http://localhost:5000) | Interface de suivi des expÃ©riences |
| ğŸš€ **API FastAPI** | [http://localhost:8000/docs](http://localhost:8000/docs) | Documentation interactive de l'API |
| ğŸ¨ **Streamlit** | [http://localhost:8501](http://localhost:8501) | Interface utilisateur graphique |

```bash
# Pour arrÃªter les services
make down
```

---

## ğŸ” Description fonctionnelle du pipeline

### ğŸ“¥ TÃ©lÃ©chargement des donnÃ©es
Via l'API Kaggle, rÃ©cupÃ©ration automatique du dataset.

### ğŸ§¹ PrÃ©traitement
- Nettoyage des valeurs manquantes
- Encodage catÃ©goriel
- CrÃ©ation de nouvelles variables:
  - `tenure_bucket`: Segmentation de l'anciennetÃ©
  - `num_services`: Nombre de services souscrits
  - `total_spend_proxy`: Estimation des dÃ©penses totales

### ğŸ¯ EntraÃ®nement
SÃ©lection automatique du modÃ¨le optimal parmi:
- ğŸŒ³ LightGBM
- ğŸš€ XGBoost
- ğŸˆ CatBoost
- ğŸ“‰ RÃ©gression Logistique

Optimisation via **Optuna** pour trouver les meilleurs hyperparamÃ¨tres.

### ğŸ“Š Suivi
Tous les paramÃ¨tres, mÃ©triques et artefacts sont enregistrÃ©s dans **MLflow**.

### âœ… Ã‰valuation
Test du modÃ¨le sur un Ã©chantillon indÃ©pendant avec mÃ©triques dÃ©taillÃ©es.

### ğŸ’¾ Enregistrement
Le meilleur modÃ¨le est promu dans le registre **MLflow**.

---

## ğŸ§ª Tests et validation

```bash
# Lancer les tests unitaires
poetry run pytest -q

# VÃ©rifier la conformitÃ© du code
poetry run ruff .
poetry run black --check .
poetry run mypy src
```

---

## â˜ï¸ DÃ©ploiement cloud (optionnel)

Pour connecter **MLflow** Ã  un backend distant (S3, GCS ou Azure):

DÃ©finissez les variables d'environnement dans un fichier `.env`:

```env
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_S3_ENDPOINT_URL=...
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
```

Relancez le projet:

```bash
docker compose up
```

---

## ğŸ–¥ï¸ Utilisation des interfaces

### ğŸš€ API FastAPI

**Endpoint principal**: `/predict`

Permet de soumettre un ou plusieurs enregistrements JSON pour obtenir une probabilitÃ© de churn.

**Exemple de requÃªte**:

```json
{
  "SeniorCitizen": 0,
  "tenure": 12,
  "MonthlyCharges": 50.5,
  "TotalCharges": 606.0,
  "Contract": "Month-to-month",
  "PaymentMethod": "Electronic check"
}
```

### ğŸ¨ Application Streamlit

Interface graphique intuitive pour:
- âœï¸ Tester des entrÃ©es manuelles
- ğŸ“Š Observer la probabilitÃ© de churn prÃ©dite
- ğŸ“ˆ Visualiser les facteurs de risque

---

## ğŸ”„ IntÃ©gration continue (CI/CD)

Les workflows **GitHub Actions** assurent:

- âœ… Analyse statique du code (black, ruff, mypy, isort)
- âœ… ExÃ©cution automatique des tests unitaires
- âœ… Construction et publication des images Docker
- âœ… Validation de la reproductibilitÃ© du pipeline

---

## ğŸ“ Commandes utiles

| Commande | Description |
|----------|-------------|
| `dvc repro` | Lancer le pipeline complet |
| `make up` | DÃ©marrer les services Docker |
| `make down` | ArrÃªter les services Docker |
| `make lint` | VÃ©rifier la qualitÃ© du code |
| `make test` | ExÃ©cuter les tests unitaires |
| `poetry run pytest` | Tests avec coverage |
| `poetry run mlflow ui` | Lancer l'interface MLflow |

---

## ğŸ“„ Licence

Le projet est distribuÃ© sous licence **MIT**.

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues! N'hÃ©sitez pas Ã :

1. ğŸ´ Fork le projet
2. ğŸŒ¿ CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push vers la branche (`git push origin feature/AmazingFeature`)
5. ğŸ”ƒ Ouvrir une Pull Request

---

## ğŸ“§ Contact

**Projet maintenu par**: [Souley225](https://github.com/Souley225)

**Repository**: [Customer_Churn_Project](https://github.com/Souley225/Customer_Churn_Project)

---

<div align="center">
  <sub>Construit avec â¤ï¸ en utilisant MLOps best practices</sub>
</div>
